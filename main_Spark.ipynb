{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "with open(\"setupPySpark.py\", \"r\") as setup_file:\n",
    "    exec(setup_file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark context\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL context\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required functions\n",
    "from util import read_file, read_folder, get_character_similarity\n",
    "from pandas import Series, DataFrame\n",
    "from util_spark import remove_stopwords_spark, detect_language_spark, flatten_list_of_tokens, spell_correct_tokens_spark, get_semantic_similarity_spark\n",
    "from tokenization_spark import tokenize_sentence_nltk_spark\n",
    "from pyspark.sql.functions import col\n",
    "from pos_tagging_spark import run_treetagger_pos_tag_spark\n",
    "from modeling_spark import run_word2vec_model_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input file(s) using python's default libraries\n",
    "in_file = open(\"in_file.cfg\").read()\n",
    "in_file = in_file.split(\"\\n\")\n",
    "patterns_file = in_file[5]\n",
    "file_folder = in_file[4]\n",
    "label = in_file[3]\n",
    "column = in_file[2]\n",
    "in_type = in_file[1]\n",
    "in_file = in_file[0]\n",
    "if file_folder == \"file\":\n",
    "    strings = read_file(in_file, in_type = in_type)\n",
    "    if in_type == \"text\":\n",
    "        strings = tokenize_sentence_nltk(strings)\n",
    "        strings = DataFrame(strings)[0]\n",
    "    elif in_type == \"html_chat\":\n",
    "        timestamp = strings[2]\n",
    "        meta_data = strings[1]\n",
    "        strings = strings[0]\n",
    "        strings[label] = meta_data[\"Comment\"]\n",
    "        labels = strings[label]\n",
    "        strings = strings[column]\n",
    "    else:\n",
    "        if label in strings.columns:\n",
    "            labels = strings[label]\n",
    "        strings = strings[column]\n",
    "else:\n",
    "    strings = read_folder(in_file, in_type = in_type)\n",
    "    patterns = Series([\".*\" + x + \".*\" for x in open(patterns_file, 'r').readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>meta_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear All\\nCan you pls. open the issue accordin...</td>\n",
       "      <td>{'From': 'Chiappin, Hana (ZUPF 2)', 'Date': 'D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Ed\\nPerfect, thank you. I will mail you a...</td>\n",
       "      <td>{'From': 'L, M (TXL 90)', 'Date': 'Freitag, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Monika,\\nThank you for your email. 11am S...</td>\n",
       "      <td>{'From': 'L, E [mailto:Ed.ligere@company.com]'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Ed\\nKindly note Ying's availability as fo...</td>\n",
       "      <td>{'From': 'L, M [mailto:m.laesser@domain.com]',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ed,\\nJanuary 24, 26 and 27 look good in m...</td>\n",
       "      <td>{'From': 'B, Y (TXC)', 'Sent': 'Donnerstag, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dear Ying,\\nThank you for your email and conta...</td>\n",
       "      <td>{'From': 'L, E [mailto:Ed.ligere@company.com]'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&gt;\\n&gt; Dear Ed,\\n&gt;\\n&gt; It was a pleasure to meet ...</td>\n",
       "      <td>{'From': 'Caiyilin, Joachim (C)\n",
       "&gt;', 'Sent': 'D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;\\n&gt; Dear Joachim,\\n&gt;\\n&gt; I was delighted to me...</td>\n",
       "      <td>{'From': 'L, E [mailto:Ed.ligere@company.com]\n",
       "...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contents  \\\n",
       "0  Dear All\\nCan you pls. open the issue accordin...   \n",
       "1  Dear Ed\\nPerfect, thank you. I will mail you a...   \n",
       "2  Dear Monika,\\nThank you for your email. 11am S...   \n",
       "3  Dear Ed\\nKindly note Ying's availability as fo...   \n",
       "4  Dear Ed,\\nJanuary 24, 26 and 27 look good in m...   \n",
       "5  Dear Ying,\\nThank you for your email and conta...   \n",
       "6  >\\n> Dear Ed,\\n>\\n> It was a pleasure to meet ...   \n",
       "7  >\\n> Dear Joachim,\\n>\\n> I was delighted to me...   \n",
       "\n",
       "                                           meta_data  \n",
       "0  {'From': 'Chiappin, Hana (ZUPF 2)', 'Date': 'D...  \n",
       "1  {'From': 'L, M (TXL 90)', 'Date': 'Freitag, 13...  \n",
       "2  {'From': 'L, E [mailto:Ed.ligere@company.com]'...  \n",
       "3  {'From': 'L, M [mailto:m.laesser@domain.com]',...  \n",
       "4  {'From': 'B, Y (TXC)', 'Sent': 'Donnerstag, 12...  \n",
       "5  {'From': 'L, E [mailto:Ed.ligere@company.com]'...  \n",
       "6  {'From': 'Caiyilin, Joachim (C)\n",
       ">', 'Sent': 'D...  \n",
       "7  {'From': 'L, E [mailto:Ed.ligere@company.com]\n",
       "...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending conversation together and creating spark data frome\n",
    "strings['conversation'] = strings['conversation'].apply(lambda x: \". \".join(x[\"Message\"]))\n",
    "sentenceDataFrame = spark.createDataFrame(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of sentences for each conversation\n",
    "sentenceDataFrame = tokenize_sentence_nltk_spark(df = sentenceDataFrame, in_col = \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language identification and filtering\n",
    "sentenceDataFrame = detect_language_spark(df = sentenceDataFrame, in_col = \"conversation\", out_col = \"language\")\n",
    "sentenceDataFrame = sentenceDataFrame.where(col('language') == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging and lemmatization using TreeTagger\n",
    "sentenceDataFrame = run_treetagger_pos_tag_spark(df = sentenceDataFrame, in_col = \"conversation\", out_col = \"pos\", get_lemma = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 2 consecutive words if a) Words are incorrectly spelled and b) Merged word is correctly spelled\n",
    "sentenceDataFrame = spell_correct_tokens_spark(df = sentenceDataFrame, in_col = \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening out token of rows and running word2vec model\n",
    "sentenceDataFrame = flatten_list_of_tokens(sentenceDataFrame, in_col = \"pos\")\n",
    "model, sentenceDataFrame = run_word2vec_model_pyspark(sentenceDataFrame, in_col = \"pos\", vec_size = 100, in_type = \"tokens\", out_col = \"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting document vectors in a list\n",
    "doc_vecs = []\n",
    "for row in sentenceDataFrame.select('result').collect():\n",
    "    doc_vecs = doc_vecs + [row['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = get_semantic_similarity_spark(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = get_character_similarity(sim1.columns, ratio_type = 'ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_ratio = get_character_similarity(sim1.columns, ratio_type = 'partial_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sort_ratio = get_character_similarity(sim1.columns, ratio_type = 'token_sort_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set_ratio = get_character_similarity(sim1.columns, ratio_type = 'token_set_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = sim1[ratio.columns]\n",
    "sim1 = sim1.loc[ratio.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_weight = 0.5\n",
    "ratio_weight = 0.4\n",
    "partial_ratio_weight = 0.4\n",
    "token_sort_ratio_weight = 0.1\n",
    "sim = 1 - (semantic_weight*sim1 + (ratio_weight*ratio + partial_ratio_weight*partial_ratio + token_sort_ratio_weight*token_sort_ratio + (1-ratio_weight-partial_ratio_weight-token_sort_ratio_weight)*token_set_ratio)*(1-semantic_weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
