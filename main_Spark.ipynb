{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "with open(\"setupPySpark.py\", \"r\") as setup_file:\n",
    "    exec(setup_file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark context\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL context\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required functions\n",
    "from util import read_file, read_folder\n",
    "from pandas import Series, DataFrame\n",
    "from util_spark import remove_stopwords_spark, detect_language_spark, flatten_list_of_tokens, spell_correct_tokens_spark, get_semantic_similarity_spark\n",
    "from tokenization_spark import tokenize_sentence_nltk_spark\n",
    "from pyspark.sql.functions import col\n",
    "from pos_tagging_spark import run_treetagger_pos_tag_spark\n",
    "from modeling_spark import run_word2vec_model_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input file(s) using python's default libraries\n",
    "in_file = open(\"in_file.cfg\").read()\n",
    "in_file = in_file.split(\"\\n\")\n",
    "patterns_file = in_file[5]\n",
    "file_folder = in_file[4]\n",
    "label = in_file[3]\n",
    "column = in_file[2]\n",
    "in_type = in_file[1]\n",
    "in_file = in_file[0]\n",
    "if file_folder == \"file\":\n",
    "    strings = read_file(in_file, in_type = in_type)\n",
    "    if in_type == \"text\":\n",
    "        strings = tokenize_sentence_nltk(strings)\n",
    "        strings = DataFrame(strings)[0]\n",
    "    elif in_type == \"html\":\n",
    "        timestamp = strings[2]\n",
    "        meta_data = strings[1]\n",
    "        strings = strings[0]\n",
    "        strings[label] = meta_data[\"Comment\"]\n",
    "        labels = strings[label]\n",
    "        strings = strings[column]\n",
    "    else:\n",
    "        if label in strings.columns:\n",
    "            labels = strings[label]\n",
    "        strings = strings[column]\n",
    "else:\n",
    "    strings = read_folder(in_file, in_type = in_type)\n",
    "    patterns = Series([\".*\" + x + \".*\" for x in open(patterns_file, 'r').readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending conversation together and creating spark data frome\n",
    "strings['conversation'] = strings['conversation'].apply(lambda x: \". \".join(x[\"Message\"]))\n",
    "sentenceDataFrame = spark.createDataFrame(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of sentences for each conversation\n",
    "sentenceDataFrame = tokenize_sentence_nltk_spark(df = sentenceDataFrame, in_col = \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language identification and filtering\n",
    "sentenceDataFrame = detect_language_spark(df = sentenceDataFrame, in_col = \"conversation\", out_col = \"language\")\n",
    "sentenceDataFrame = sentenceDataFrame.where(col('language') == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging and lemmatization using TreeTagger\n",
    "sentenceDataFrame = run_treetagger_pos_tag_spark(df = sentenceDataFrame, in_col = \"conversation\", out_col = \"pos\", get_lemma = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 2 consecutive words if a) Words are incorrectly spelled and b) Merged word is correctly spelled\n",
    "sentenceDataFrame = spell_correct_tokens_spark(df = sentenceDataFrame, in_col = \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening out token of rows and running word2vec model\n",
    "sentenceDataFrame = flatten_list_of_tokens(sentenceDataFrame, in_col = \"pos\")\n",
    "model, sentenceDataFrame = run_word2vec_model_pyspark(sentenceDataFrame, in_col = \"pos\", vec_size = 100, in_type = \"tokens\", out_col = \"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting document vectors in a list\n",
    "doc_vecs = []\n",
    "for row in sentenceDataFrame.select('result').collect():\n",
    "    doc_vecs = doc_vecs + [row['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = get_semantic_similarity_spark(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>for</th>\n",
       "      <th>this</th>\n",
       "      <th>in</th>\n",
       "      <th>move</th>\n",
       "      <th>have</th>\n",
       "      <th>your</th>\n",
       "      <th>point</th>\n",
       "      <th>guy</th>\n",
       "      <th>b2b</th>\n",
       "      <th>agree</th>\n",
       "      <th>...</th>\n",
       "      <th>no</th>\n",
       "      <th>we</th>\n",
       "      <th>let</th>\n",
       "      <th>ramification</th>\n",
       "      <th>when</th>\n",
       "      <th>away</th>\n",
       "      <th>and</th>\n",
       "      <th>today</th>\n",
       "      <th>the</th>\n",
       "      <th>cant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>-0.322402</td>\n",
       "      <td>-0.046452</td>\n",
       "      <td>-0.219655</td>\n",
       "      <td>-0.110043</td>\n",
       "      <td>-0.117959</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>0.066608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098829</td>\n",
       "      <td>-0.086558</td>\n",
       "      <td>0.045495</td>\n",
       "      <td>-0.139093</td>\n",
       "      <td>0.093950</td>\n",
       "      <td>-0.083673</td>\n",
       "      <td>-0.063062</td>\n",
       "      <td>-0.043828</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.038780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.088893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141377</td>\n",
       "      <td>0.081572</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>0.150715</td>\n",
       "      <td>-0.107207</td>\n",
       "      <td>-0.239497</td>\n",
       "      <td>0.121205</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087727</td>\n",
       "      <td>0.188562</td>\n",
       "      <td>-0.029192</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>-0.220844</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.009694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.141377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196407</td>\n",
       "      <td>-0.134500</td>\n",
       "      <td>0.135836</td>\n",
       "      <td>-0.093180</td>\n",
       "      <td>-0.016781</td>\n",
       "      <td>0.064896</td>\n",
       "      <td>-0.233312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114512</td>\n",
       "      <td>0.047512</td>\n",
       "      <td>-0.249753</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>-0.093499</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.144752</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>move</th>\n",
       "      <td>-0.322402</td>\n",
       "      <td>0.081572</td>\n",
       "      <td>-0.196407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124379</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>-0.024179</td>\n",
       "      <td>-0.039517</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.166068</td>\n",
       "      <td>0.013840</td>\n",
       "      <td>0.226505</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>-0.191075</td>\n",
       "      <td>0.168643</td>\n",
       "      <td>0.175773</td>\n",
       "      <td>0.113304</td>\n",
       "      <td>0.036050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>-0.046452</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>-0.134500</td>\n",
       "      <td>0.124379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078544</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>-0.025583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009402</td>\n",
       "      <td>0.232484</td>\n",
       "      <td>0.042098</td>\n",
       "      <td>0.077349</td>\n",
       "      <td>0.049321</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.074480</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.094947</td>\n",
       "      <td>0.199208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           for      this        in      move      have      your     point  \\\n",
       "for   1.000000  0.088893  0.172195 -0.322402 -0.046452 -0.219655 -0.110043   \n",
       "this  0.088893  1.000000  0.141377  0.081572  0.130635  0.150715 -0.107207   \n",
       "in    0.172195  0.141377  1.000000 -0.196407 -0.134500  0.135836 -0.093180   \n",
       "move -0.322402  0.081572 -0.196407  1.000000  0.124379  0.142081 -0.001474   \n",
       "have -0.046452  0.130635 -0.134500  0.124379  1.000000 -0.078544  0.052904   \n",
       "\n",
       "           guy       b2b     agree    ...           no        we       let  \\\n",
       "for  -0.117959 -0.007950  0.066608    ...    -0.098829 -0.086558  0.045495   \n",
       "this -0.239497  0.121205  0.032268    ...     0.087727  0.188562 -0.029192   \n",
       "in   -0.016781  0.064896 -0.233312    ...     0.114512  0.047512 -0.249753   \n",
       "move -0.024179 -0.039517 -0.001032    ...     0.026875  0.166068  0.013840   \n",
       "have  0.018566  0.022026 -0.025583    ...    -0.009402  0.232484  0.042098   \n",
       "\n",
       "      ramification      when      away       and     today       the      cant  \n",
       "for      -0.139093  0.093950 -0.083673 -0.063062 -0.043828  0.126474  0.038780  \n",
       "this      0.065307  0.017507 -0.021388 -0.220844  0.021283  0.026640 -0.009694  \n",
       "in        0.033340 -0.093499  0.074829 -0.058607  0.144752  0.011207  0.004448  \n",
       "move      0.226505  0.034336 -0.191075  0.168643  0.175773  0.113304  0.036050  \n",
       "have      0.077349  0.049321  0.043578  0.074480  0.036704  0.094947  0.199208  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
